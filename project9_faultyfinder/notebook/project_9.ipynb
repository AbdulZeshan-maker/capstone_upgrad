{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0928ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import seaborn as sns\n",
    "\n",
    "# Data paths\n",
    "good_images_path = '/path/to/good/folder'  # replace with the actual path\n",
    "defective_images_path = '/path/to/defective/folder'  # replace with the actual path\n",
    "\n",
    "# Image parameters\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "\n",
    "# Image Data Generators for preprocessing and augmentation\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "# Train and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=os.path.dirname(good_images_path),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='training')  # Set for training data\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    directory=os.path.dirname(good_images_path),\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    subset='validation')  # Set for validation data\n",
    "\n",
    "# Model architecture: Convolutional Neural Network (CNN)\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Set early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_acc = model.evaluate(validation_generator)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_acc}\")\n",
    "\n",
    "# Visualize training results\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix and classification report\n",
    "validation_generator.reset()\n",
    "Y_pred = model.predict(validation_generator)\n",
    "y_pred = (Y_pred > 0.5).astype(int)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "cm = confusion_matrix(validation_generator.classes, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=['Good', 'Defective']))\n",
    "\n",
    "# Save the model for future use\n",
    "model.save('faultfindy_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdf78cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Conv layer with variable number of filters and kernel size\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_1_filter', values=[32, 64, 128]),\n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu',\n",
    "                     input_shape=(img_height, img_width, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Second Conv layer\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_2_filter', values=[64, 128]),\n",
    "                     kernel_size=hp.Choice('conv_2_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Third Conv layer\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_3_filter', values=[128, 256]),\n",
    "                     kernel_size=hp.Choice('conv_3_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layer with variable number of units\n",
    "    model.add(Dense(units=hp.Int('dense_units', min_value=128, max_value=512, step=32), activation='relu'))\n",
    "\n",
    "    # Dropout layer with variable dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with variable learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner object for RandomSearch\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter configurations to try\n",
    "    executions_per_trial=1,  # Number of models to build and evaluate per configuration\n",
    "    directory='faultfindy_tuning',  # Directory to save results\n",
    "    project_name='faultfindy_cnn'\n",
    ")\n",
    "\n",
    "# Print a summary of the search space\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Retrieve the best hyperparameters and model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(f\"Best number of conv_1 filters: {best_hps.get('conv_1_filter')}\")\n",
    "print(f\"Best kernel size for conv_1: {best_hps.get('conv_1_kernel')}\")\n",
    "print(f\"Best dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Best dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Train the best model on full data\n",
    "best_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate the best model\n",
    "val_loss, val_acc = best_model.evaluate(validation_generator)\n",
    "print(f\"Best Model Validation Loss: {val_loss}\")\n",
    "print(f\"Best Model Validation Accuracy: {val_acc}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1456792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define a model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # First Conv layer with variable number of filters and kernel size\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_1_filter', values=[32, 64, 128]),\n",
    "                     kernel_size=hp.Choice('conv_1_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu',\n",
    "                     input_shape=(img_height, img_width, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Second Conv layer\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_2_filter', values=[64, 128]),\n",
    "                     kernel_size=hp.Choice('conv_2_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    # Third Conv layer\n",
    "    model.add(Conv2D(filters=hp.Choice('conv_3_filter', values=[128, 256]),\n",
    "                     kernel_size=hp.Choice('conv_3_kernel', values=[(3, 3), (5, 5)]),\n",
    "                     activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Dense layer with variable number of units\n",
    "    model.add(Dense(units=hp.Int('dense_units', min_value=128, max_value=512, step=32), activation='relu'))\n",
    "\n",
    "    # Dropout layer with variable dropout rate\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model with variable learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Instantiate the tuner object for RandomSearch\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter configurations to try\n",
    "    executions_per_trial=1,  # Number of models to build and evaluate per configuration\n",
    "    directory='faultfindy_tuning',  # Directory to save results\n",
    "    project_name='faultfindy_cnn'\n",
    ")\n",
    "\n",
    "# Print a summary of the search space\n",
    "tuner.search_space_summary()\n",
    "\n",
    "# Perform the hyperparameter search\n",
    "tuner.search(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Retrieve the best hyperparameters and model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Display the best hyperparameters\n",
    "print(f\"Best number of conv_1 filters: {best_hps.get('conv_1_filter')}\")\n",
    "print(f\"Best kernel size for conv_1: {best_hps.get('conv_1_kernel')}\")\n",
    "print(f\"Best dropout rate: {best_hps.get('dropout_rate')}\")\n",
    "print(f\"Best dense units: {best_hps.get('dense_units')}\")\n",
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "\n",
    "# Train the best model on full data\n",
    "best_model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate the best model\n",
    "val_loss, val_acc = best_model.evaluate(validation_generator)\n",
    "print(f\"Best Model Validation Loss: {val_loss}\")\n",
    "print(f\"Best Model Validation Accuracy: {val_acc}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
