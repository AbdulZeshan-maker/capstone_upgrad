{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb6d64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the datasets\n",
    "customer_df = pd.read_csv('/mnt/data/Customer.csv')\n",
    "prod_cat_df = pd.read_csv('/mnt/data/prod_cat_info.csv')\n",
    "transactions_df = pd.read_csv('/mnt/data/Transactions.csv')\n",
    "\n",
    "# Display the first few rows of each dataframe to understand the structure\n",
    "print(\"Customer DataFrame:\")\n",
    "display(customer_df.head())\n",
    "\n",
    "print(\"Product Category DataFrame:\")\n",
    "display(prod_cat_df.head())\n",
    "\n",
    "print(\"Transactions DataFrame:\")\n",
    "display(transactions_df.head())\n",
    "\n",
    "# Check the basic info and structure of each dataset\n",
    "print(\"\\nCustomer DataFrame Info:\")\n",
    "customer_df.info()\n",
    "\n",
    "print(\"\\nProduct Category DataFrame Info:\")\n",
    "prod_cat_df.info()\n",
    "\n",
    "print(\"\\nTransactions DataFrame Info:\")\n",
    "transactions_df.info()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in Customer DataFrame:\")\n",
    "print(customer_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Product Category DataFrame:\")\n",
    "print(prod_cat_df.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Transactions DataFrame:\")\n",
    "print(transactions_df.isnull().sum())\n",
    "\n",
    "# Check for duplicates in each dataset\n",
    "print(\"\\nDuplicates in Customer DataFrame:\", customer_df.duplicated().sum())\n",
    "print(\"Duplicates in Product Category DataFrame:\", prod_cat_df.duplicated().sum())\n",
    "print(\"Duplicates in Transactions DataFrame:\", transactions_df.duplicated().sum())\n",
    "\n",
    "# Merge the datasets to form a single table for recommendation system analysis\n",
    "# Assuming 'prod_cat_code' is a linking key between Transactions and Product Category DataFrames\n",
    "merged_df = pd.merge(transactions_df, prod_cat_df, on='prod_cat_code', how='left')\n",
    "\n",
    "# Assuming 'customer_Id' is the key to link Transactions and Customer DataFrames\n",
    "merged_df = pd.merge(merged_df, customer_df, on='customer_Id', how='left')\n",
    "\n",
    "# Display the first few rows of the merged dataframe\n",
    "print(\"\\nMerged DataFrame:\")\n",
    "display(merged_df.head())\n",
    "\n",
    "# Explore the merged data\n",
    "print(\"\\nMerged DataFrame Info:\")\n",
    "merged_df.info()\n",
    "\n",
    "# Visualizing some important relationships (optional, can be skipped for the next steps)\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(data=merged_df, x='Gender')\n",
    "plt.title('Gender Distribution of Customers')\n",
    "plt.show()\n",
    "\n",
    "# Save the merged dataframe for future use\n",
    "merged_df.to_csv('/mnt/data/merged_recommender_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d0547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for building the collaborative filtering model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from surprise import Dataset, Reader\n",
    "from surprise import SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Prepare the data for collaborative filtering\n",
    "# We'll use 'customer_Id' and 'prod_cat_code' for this purpose\n",
    "ratings_data = merged_df[['customer_Id', 'prod_cat_code']]\n",
    "\n",
    "# Adding a dummy 'rating' column for recommendation purposes\n",
    "ratings_data['rating'] = 1  # This can be modified later based on actual customer ratings\n",
    "\n",
    "# Use Surprise library to build a collaborative filtering model\n",
    "# Reader helps to define the rating scale, but since we have binary ratings (purchased or not), we can set min=0, max=1\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "data = Dataset.load_from_df(ratings_data[['customer_Id', 'prod_cat_code', 'rating']], reader)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "trainset, testset = train_test_split(ratings_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Using SVD (Singular Value Decomposition) for collaborative filtering\n",
    "svd_model = SVD()\n",
    "\n",
    "# Perform 5-fold cross-validation on the SVD model\n",
    "cross_validate(svd_model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Train the SVD model on the full training data\n",
    "train_data = data.build_full_trainset()\n",
    "svd_model.fit(train_data)\n",
    "\n",
    "# Make predictions for a specific user (for example, customer_Id = 1)\n",
    "customer_id = 1\n",
    "product_id = 2  # example product category code\n",
    "\n",
    "# Predict the rating for this customer-product pair\n",
    "prediction = svd_model.predict(customer_id, product_id)\n",
    "print(f\"Predicted rating for customer {customer_id} and product {product_id}: {prediction.est}\")\n",
    "\n",
    "# Get top N product recommendations for a specific customer\n",
    "def get_top_n_recommendations(model, customer_id, product_ids, n=5):\n",
    "    predictions = [model.predict(customer_id, pid) for pid in product_ids]\n",
    "    recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
    "    return [(pred.iid, pred.est) for pred in recommendations]\n",
    "\n",
    "# Example usage: Get top 5 recommended products for customer with ID 1\n",
    "unique_products = merged_df['prod_cat_code'].unique()\n",
    "top_n_recommendations = get_top_n_recommendations(svd_model, customer_id, unique_products, n=5)\n",
    "\n",
    "print(f\"Top 5 product recommendations for customer {customer_id}: {top_n_recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86d4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for content-based filtering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# We'll use the product category names to find similar products\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "# Replace missing values in 'prod_cat_name' with empty string\n",
    "prod_cat_df['prod_cat_name'] = prod_cat_df['prod_cat_name'].fillna('')\n",
    "\n",
    "# Fit and transform the 'prod_cat_name' column\n",
    "tfidf_matrix = tfidf.fit_transform(prod_cat_df['prod_cat_name'])\n",
    "\n",
    "# Compute the cosine similarity matrix between products\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Function to get recommendations based on product similarity\n",
    "def get_content_based_recommendations(product_id, cosine_sim=cosine_sim, prod_cat_df=prod_cat_df, n=5):\n",
    "    # Get the index of the product that matches the product_id\n",
    "    idx = prod_cat_df[prod_cat_df['prod_cat_code'] == product_id].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all products with the selected product\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the products based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the indices of the n most similar products\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "\n",
    "    # Get the product indices\n",
    "    product_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top n most similar products\n",
    "    return prod_cat_df['prod_cat_code'].iloc[product_indices]\n",
    "\n",
    "# Example: Get top 5 products similar to product with 'prod_cat_code' = 2\n",
    "similar_products = get_content_based_recommendations(2, n=5)\n",
    "print(f\"Top 5 similar products to product 2: {similar_products.tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Example ground truth and predicted data for illustration\n",
    "# y_true: Actual purchases (1 if product purchased, 0 if not)\n",
    "# y_pred: Model's prediction (1 if product recommended, 0 if not)\n",
    "# These should ideally come from your test data and the model's recommendations\n",
    "\n",
    "# Example data for demonstration (adjust based on actual data)\n",
    "y_true = [1, 1, 0, 0, 1, 0, 1, 0, 0, 1]  # Actual purchases\n",
    "y_pred = [1, 0, 0, 1, 1, 0, 1, 1, 0, 1]  # Predicted recommendations\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Display the results\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
